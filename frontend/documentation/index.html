<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sentinel Auth API Docs - AI Agent Integration</title>
    <link rel="stylesheet" href="/styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;500&family=Space+Grotesk:wght@400;500;700&display=swap"
        rel="stylesheet">
</head>

<body>
    <div class="page-shell">
        <main class="layout">
            <nav class="topbar panel">
                <a class="brand-link" href="/">Sentinel Auth</a>
                <div class="topbar-links">
                    <a class="topbar-link" href="/documentation/index.html">Documentation</a>
                    <a class="topbar-link" href="/">Developer Portal</a>
                    <a class="topbar-link" href="/activity.html">Activity Feed</a>
                    <a class="topbar-link topbar-link-active" href="/docs">Documentation</a>
                </div>
            </nav>

            <section class="hero panel">
                <p class="eyebrow">API Documentation</p>
                <h1>AI Agent Integration</h1>
                <p class="hero-copy">
                    Learn how to route your LLM assistants, autonomous agents, and AI bots through the
                    Sentinel Auth policy engine.
                    Ensure your agents operate within strict financial boundaries backed by Solana state proofs.
                </p>
            </section>

            <section class="grid" style="grid-template-columns: 1fr;">
                <section class="panel">
                    <div class="section-heading">
                        <p class="eyebrow">Guide</p>
                        <h2>Using LLM Tool Calling with Sentinel</h2>
                    </div>
                    <p class="muted">
                        When building agents with APIs like Google Gemini, OpenAI, or Anthropic, you should expose the Sentinel Auth proxy as an
                        available function or tool. Instead of letting the AI model directly hit live APIs, you
                        intercept its intent and validate it against your security policy.
                    </p>

                    <div class="output-card">
                        <h3>1. Model Tool Definition</h3>
                        <p class="muted">Add a schema similar to this to your agent's tool/function definitions:</p>
                        <pre class="snippet">
{
  "name": "request_action_authorization",
  "description": "Request permission to perform a financial or high-risk action.",
  "parameters": {
    "type": "object",
    "properties": {
      "action_type": { "type": "string" },
      "http_method": { "type": "string", "enum": ["GET", "POST", "PUT", "DELETE"] },
      "resource": { "type": "string" },
      "amount_usd": { "type": "number" },
      "reasoning": { "type": "string", "description": "Detailed reasoning for why this action is necessary." }
    },
    "required": ["action_type", "http_method", "resource", "amount_usd", "reasoning"]
  }
}</pre>
                    </div>

                    <div class="output-card">
                        <h3>2. Submitting to Sentinel Auth</h3>
                        <p class="muted">When the LLM decides to call the tool, parse its arguments and submit a POST
                            request to the <code>/v1/authorize</code> endpoint of your Sentinel instance.</p>
                        <pre class="snippet">
// Parse the tool/function arguments returned by Gemini/OpenAI/Claude
const agentArguments = JSON.parse(toolCall.arguments);

const res = await fetch(`https://api.sentinel-auth.com/v1/authorize`, {
  method: "POST",
  headers: {
    "Authorization": `Bearer ${process.env.SENTINEL_API_KEY}`,
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    policy_id: "pol_active_policy_id",
    requester: "agent://llm_bot_v1",
    action: {
      type: agentArguments.action_type,
      http_method: agentArguments.http_method,
      resource: agentArguments.resource,
      amount_usd: agentArguments.amount_usd
    },
    reasoning_trace: agentArguments.reasoning
  })
});

const authorizationResponse = await res.json();
// Send this response back to the LLM so it knows if it was approved or blocked!</pre>
                    </div>

                    <div class="output-card">
                        <h3>3. Handling the Decision</h3>
                        <p class="muted">Depending on what Sentinel Auth returns, handle the authorization flow:</p>
                        <ul class="muted" style="margin-left: 20px; margin-top: 10px; line-height: 1.8;">
                            <li><strong>200 OK:</strong> The action is approved. You will receive a
                                <code>receipt_signature</code> anchored on Solana. Proceed to execute the real API call.</li>
                            <li><strong>402 Payment Required:</strong> The amount exceeds the
                                <code>HIGH_RISK_THRESHOLD</code>. You must use an x402 token or sign a Solana
                                transaction to approve the risk.</li>
                            <li><strong>403 Forbidden:</strong> The AI model attempted an action that violated the
                                active safety policy (e.g., over spend limit). Reject the action.</li>
                        </ul>
                    </div>
                </section>
            </section>
        </main>
    </div>
</body>

</html>
